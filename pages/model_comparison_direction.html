<!DOCTYPE html>
<html>

<head>
  <meta charset='utf-8'>
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="description" content="Project inference : Design an experiment which requires human subjects to do inference, analyse, mine and model their behavior to understand whether/how they do inference ?">
  <link rel="stylesheet" type="text/css" media="screen" href="../stylesheets/stylesheet.css">
  <link rel="stylesheet" href="../fonts/Serif/cmun-serif.css" />

  <!--Mathematics with MathJax-->
  <script type="text/x-mathjax-config">      
    MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true
  },
  "HTML-CSS": { 
  availableFonts: ["STIX"],
}
});
</script>
<script type="text/javascript" async
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
</script>  

</head>

<body>

  <title>Model comparison direction task</title>

  <!-- HEADER -->
  <div id="header_wrap" class="outer">
    <header class="inner">
      <a id="forkme_banner" href="https://github.com/steevelaquitaine/projInference">Github</a>
      <a id="project_author" href="http://steevelaquitaine.blogspot.com">Steeve laquitaine </a>
    </header>
  </div>

  <!--TITLE-->
  <div id="proj_title_wrap" class="outer">
    <header class="inner">
      <section id="proj_title" class="inner">
        <h1 id="proj_title"> Model comparison direction task </h1>
      </section>
    </div>

    <!--Table of contents    -->
    <div id="Table_of_content_wrap" class="outer">
      <section id="table_of_content" class="inner">
        <h5 id="top"> TABLE OF CONTENTS </h5>       
        <h7><a href="#briefly"> <b>Briefly </b><br></h7>
        <h7><a href="#BBO">       &nbsp Bayes MAP <br></h7>
        <h7><a href="#SLP">       &nbsp Switching between LLH and prior <br></h7>
        <h7><a href="#SPP">       &nbsp Switching between posterior and prior <br></h7>
        <h7><a href="#BS">        &nbsp Basic Sampling <br></h7>
        <h7><a href="#BLTL">      &nbsp Bayes BLS tailed LLH <br></h7>
        <h7><a href="#BLTLMAP">   &nbsp Bayes MAP tailed LLH<br></h7>
        <h7><a href="#BMME">      &nbsp Bayes MAP motion energy model <br></h7>
        <h7><a href="#BLTP">      &nbsp Bayes MAP tailed prior <br></h7>
        <h7><a href="#BC">        &nbsp Bayes cardinal <br></h7>
        <h7><a href="#BSC">       &nbsp Bayes sampling cardinal <br></h7>
        <h7><a href="#BLTL">      &nbsp Bayes BLS tailed LLH and tailed prior <br></h7>
        <h7><a href="#BvS">       &nbsp Switching vs basic Bayes <br></h7>
        <h7><a href="#aicdiff">   &nbsp AIC differences <br></h7>        
        <h7><a href="#foc">       &nbsp Fminsearch options for convergence <br></h7>        
        <h7><a href="#HI">        &nbsp &nbsp &nbsp High iterations : TolFun = 1e-4, TolX = 1e-4 MaxIter = 2000*numFitP, MaxFunEvals = 10*2000*numFitP <br></h7><h7><a>        
        <h7><a href="#switchingfitp">  Table of switching best fit parameters <br></h7><h7><a>

      </section>
    </div>    


    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">   

        <p><h7><a id="briefly" class="anchor" href="#briefly" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Briefly</b></a></h7> </p>                

        <p> We first searched for reasonable initial parameters that reproduced estimate distributions best alternating manual tuning of initial paramaters with quick fminsearch fits of the. Graphical fitting indicated that predicted distributions were very sensitive to the magnitude of the initial parameters such as changing priors by 0.1 can sometimes evidently changed estimate distribution shapes and log likelihood of the data given the model </p>

        <p><h7><a id="BBO" class="anchor" href="#BBO" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Bayes MAP </b></a></h7> </p>                

        <p>We searched graphically the initial parameters that matched best the estimate mean, std and distributions</p>

        <code class="code">
          datapath = '~/Desktop/dataPsychophy/proj01_priorStrength'; <br>
          output = SLfitBayesianModel({'sub01'},[80 40 20 1.74 4.77 10.74 34.25 0 0.001 15 NaN],,'pscaling',ones(1,11), 'dataPathVM', datapath, 'experiment','vonMisesPrior','filename','datafit','MAPReadout','modelPredictions','withData','inputFitParameters');
        </code>

        <p>The best matching initial parameters were, for each subject (rows) : </p>

        <code class="code">
          initp = [80 40 20 1.74 4.77 10.74 34.25 0 0.001 15 NaN] 
          101 70 22 1 3 9.74 34 NaN 0.0007 6.9 NaN;
          80 40 16 1.7 4.8 11 33 NaN 0.00039 17 NaN;
          79.3 38.9 9.19 1.7 4.8 11 33 NaN 0.00039 17 NaN;
          80 5 1 0 0 0 0 NaN 0.001 13.5 NaN;
          30 3 1 0.01 1.001 1.7 2 NaN 0.001 15 NaN;
          80 35 15 1.74 4.77 10.74 34.25 NaN 0.001 13.5 NaN;
          60 10 5 1.535 4.3425 10.62 40 NaN 0.00062 13.975 NaN;
          25 3 1.5 0.01 0.2 2 3.2 NaN 0.001 15 NaN;
          200 1 1 0.18 1 21.63 300.63 NaN 0.00104 5 NaN;
          25 3 1.5 0.06 0.2 2.1 3.4 NaN 0.001 15 NaN;
          5 2 1 0.01 1.00015 1.035 3 NaN 0.001 15 NaN];
        </code>

        <p>We then fit each subject data </p>

        <code class="code">
          output = SLfitBayesianModel({'sub01'},[80 40 20 1.74 4.77 10.74 34.25 NaN 0.001 15 NaN],'pscaling',ones(1,11), 'dataPathVM', datapath, 'experiment', 'vonMisesPrior', 'filename', 'datafit', 'MAPReadout', 'MaxLikelihoodFit', 'fminsearch');
        </code>

        <p>Note that after reviewer's comment on fitting convergence, I checked convergence parameters of fminsearch. Exitflags were zero for some of the initial parametersindicating that the algorithm stopped before reaching its default tolerance functions for the minimum change in the objective function and the model parameters (TolFun and TolX = 1e-4). I then rerun the fit with 10 times more iterations (now 2000*number of parameters instead of 200*number of parameters) and function evaluations (now 10*2000*number of parameters).This was true for all subjects. Increasing maxiter led to convergence for all subjects and all initial parameters </p>

        <!--SECTION-->
        <p><h7><a id="SLP" class="anchor" href="#BLTL" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Switching between LLH and prior </b></a></h7> </p>  

        <p> We searched for initial parameters graphically : </p>

        <code class= "code">
          datapath = '~/Desktop/dataPsychophy/proj01_priorStrength'; <br>
          output = SLfitCompetitionModel({'sub01'},
          [80 30 2 0.7 3 7 33 NaN 0.001 30],
          'dataPathVM',datapath,'experiment','vonMisesPrior',
          'modelPredictions','withData',
          'inputFitParameters',
          'filename','fitswitchLLHorPrior');            
        </code>

        <p> The best matching initial parameters were, for each subject (rows) : </p>

        <code class= "code">
         initp = [80 30 2 0.7 3 7 33 NaN 0.001 30;
         80 2 1 1.74 4.77 60 100 NaN 0.001 15;
         80 40 3 1.74 4.77 30 40 NaN 0.001 15;
         80 3 0.5 0.3 0.9 3 21 NaN 0.001 15;
         80 20 .5 0 0 0 0 NaN 0.001 15;
         80 4 1 0 3 21 25 NaN 0.001 15;
         80 6 2 0.3 3 10.74 21 NaN 0.001 18;
         80 1 0.4 0.1 2 2 5 NaN 0.001 3;
         80 16 2 0.1 0.7 10 10 NaN 0.001 18;
         200 1 1 0.18 1 21.63 300.63 NaN 0.00104 5;
         80 3 1 0.00005 0.2 3 15 NaN 0.001 30;
         5 2.5 1 0.3 1.7 6 33 NaN 0.001 17]
       </code>

       <p>We then fitted the model to the data</p>

       <code class="code">        
        clear <br>          
        tic <br>
        subject = {'sub01','sub02','sub03','sub04','sub05','sub06','sub07',
        'sub08','sub09','sub10','sub11','sub12'};<br>
        datapath = '/Desktop/dataPsychophy/proj01_priorStrength/data'<br>
        pscales = ones(6,10) <br><br>

        for i = 1 : length(subject)<br>
        output = SLfitCompetitionModel(subject(i),initp(i,:),
        'pscaling',pscales(i,:),
        'dataPathVM',datapath,'experiment','vonMisesPrior',
        'MaxLikelihoodFit','fminsearch',
        'filename','datafitsw');<br>                 
        end
        toc
      </code>

      <p> Note that after reviewer's comment on fitting convergence, I checked convergence parameters of fminsearch. Exitflags were zero for some of the initial parameters (for example for subject 2) indicating that the algorithm stopped before reaching its default tolerance functions for the minimum change in the objective function and the model parameters (TolFun and TolX = 1e-4). I then rerun the fit with 10 times more iterations (now 2000*number of parameters instead of 200*number of parameters) and function evaluations (now 10*2000*number of parameters). This was true for subjects 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12. Increasing iterations led to convergence. </p>    

      <p> We run model comparison :</p>

      <code class="code">
        path = '~/Desktop/dataPsychophy/proj01_priorStrength/modelfit/AIC/'; 
        model_ref = 'model_CompDiv'; 
        models = {'model_CompDivPostorPrior'}; 
        [AICsvsSw,semAICsvsSw,aicDiff] = slPlotModelsAICvsSwitchingAIC(model_ref,models,path); 
        [e,ci,m,s] = slMakeCI(aicDiff,0.95); 
      </code>

      <p>The average AIC difference was 31 </p>


      <!--section-->
      <p><h7><a id="SPP" class="anchor" href="#BLTL" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Switching between posterior and prior</b></a></h7> </p>  
      <p></p>

      <p>We searched for initial parameters by matching predictions and estimate distribution best : </p>

      <code class= "code">
        datapath = '~/Desktop/dataPsychophy/proj01_priorStrength'; <br>
        output = SLfitCompetitionModel({'sub01'},
        [80 30 2 0.7 5 7 33 NaN 0.001 30],
        'dataPathVM',datapath,'experiment','vonMisesPrior',
        'modelPredictions','withData',
        'inputFitParameters',
        'filename','fitswitchPostorPrior',
        'switchPostorPrior');            
      </code>

      <p> When initialise the search with the same initial parameters as for the Switching between likelihood and prior observer. The peak observed at the motion direction was slightly shifted in between motion direction and prior in that new model consistent with prior and likelihood integration into a posterior that peaks in between prior and likelihood. The best matching initial parameters were found by increasing likelihood strength and sometimes weakening priors to shift the peak back at the motion direction. Initial parameters were, for each subject (rows) : </p>

      <code class= "code">
        initp = [100 60 5 0.7 5 7 33 NaN 0.001 30;
        100 4 2 1.74 4.77 60 100 NaN 0.001 15;
        150 100 6 1.74 4.77 30 40 NaN 0.001 15;
        100 6 1 0.3 0.9 3 21 NaN 0.001 15;
        90 30 1 0 0 0 0 NaN 0.001 15;
        160 8 2 0.4 0.5 3 5 NaN 0.001 15;
        100 12 3 0.2 1.5 6 15 NaN 0.001 18;
        80 1 0.4 0.1 2 2 5 NaN 0.001 3;
        90 18 3 0.55 0.55 8 9 NaN 0.001 18;
        300 1 1 0.18 1 21.63 300.63 NaN 0.00104 5;
        90 5 2 0.2 0.2 3 15 NaN 0.001 30;
        10 5 2 0.3 1.7 6 33 NaN 0.001 17];
      </code>

      <p>We then fitted the model to the data</p>

      <code class="code">        
        clear <br>          
        tic <br>
        subject = {'sub01','sub02','sub03','sub04','sub05','sub06','sub07',
        'sub08','sub09','sub10','sub11','sub12'};<br>
        datapath = '/Desktop/dataPsychophy/proj01_priorStrength/data'<br>
        pscales = ones(12,10) <br><br>

        for i = 1 : length(subject)<br>
        output = SLfitCompetitionModel(subject(i),initp(i,:),
        'pscaling',pscales(i,:),
        'dataPathVM',datapath,'experiment','vonMisesPrior',
        'MaxLikelihoodFit','fminsearch',
        'filename','datafitswPoOrPr',
        'switchPostorPrior');<br>                 
        end
        toc
      </code>

      <p>Note that after reviewer's comment on fitting convergence, I checked convergence parameters of fminsearch. Exitflags were zero for some of the initial parameters (for example for subject 2) indicating that the algorithm stopped before reaching its default tolerance functions for the minimum change in the objective function and the model parameters (TolFun and TolX = 1e-4). I then rerun the fit with 10 times more iterations (now 2000*number of parameters instead of 200*number of parameters) and function evaluations (now 10*2000*number of parameters). This was true for all subjects. Increasing iterations led to convergence. </p>


      <!-- SECTION -->
      <p><h7><a id="BS" class="anchor" href="#BS" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Bayes Sampling </b></a></h7> </p>          

      <p>We manually searched the initial parameters that best graphically reproduced the data </p>

      <code class="code">
        datapath = '~/Desktop/dataPsychophy/proj01_priorStrength'; <br>        
        SLfitBayesianModel({'sub01'},[100 20 4 1.5 5 10 34 NaN 0.001 75 NaN],... <br>
        'dataPathVM',datapath,'inputFitParameters','experiment','vonMisesPrior','filename',...<br>
        'predFile','SamplingReadout','modelPredictions','withData');
      </code>

      <p>Best initial parameters were </p>

      <code class= "code">
        initp = [100 20 4 1.5 5 10 34 NaN 0.001 75 NaN;
        10 2.5 1.5 2 5 10 34 NaN 0.001 75 NaN;
        100 10 4 2 5 10 34 NaN 0.001 75 NaN;
        10. 4. 1.70 1.70 3.50 10. 34. NaN 0.001 75.00 NaN;
        40 4 1.70 0 0 0 0 NaN 0.001 75.00 NaN;
        15.00 4.00 2.00 0.50 3.50 10.00 34.00 NaN 0.001 75.00 NaN;
        35.00 7.00 2.00 0.50 2.00 7.00 34.00 NaN 0.001 75.00 NaN;
        4.00 2.00 1.00 0.50 1.50 2.00 2.50 NaN 0.001 75.00 NaN;
        30.00 4.00 2.00 0.50 1.00 6.00 6.00 NaN 0.001 75.00 NaN;
        200.00 3.00 1.60 0.01 1.00 21.63 300.63 NaN 0.001 5.00 NaN;
        30.00 4.00 2.00 0.20 1.00 3.00 10.00 NaN 0.001 75.00 NaN;
        5.00 2.00 1.50 0.15 1.00 3.00 10.00 NaN 0.001 75.00 NaN]
      </code>    

      <p> We then fitted model to each subject data </p>

      <code class="code">      
        tic <br>
        subject = {'sub01','sub02','sub03','sub04','sub05','sub06','sub07', 'sub08','sub09','sub10','sub11','sub12'};<br>
        datapath = '/Desktop/dataPsychophy/proj01_priorStrength/data'<br>
        pscales = ones(6,11);<br><br>

        for i = 1 : length(subject)<br>
        output = slshortfitBayesSmp(subject(i),initp(i,:),pscales(i,:),datapath);<br>
        end<br>
        toc<br>

      </code>

      <p>Note that after reviewer's comment on fitting convergence, I checked convergence parameters of fminsearch. Exitflags were zero for some of the initial parameters indicating that the algorithm stopped before reaching its default tolerance functions for the minimum change in the objective function and the model parameters (TolFun and TolX = 1e-4). I then rerun the fit with 10 times more iterations (now 2000*number of parameters instead of 200*number of parameters) and function evaluations (now 10*2000*number of parameters). Subjects concerned were subjects 9 and 10. Increasing iterations led to convergence for all initial parameters.</p>

      <code class="code">      
        tic <br>
        subject = {'sub09','sub10'};<br>
        datapath = '~/Desktop/dataPsychophy/proj01_priorStrength/data'<br>
        pscales = ones(2,11);<br><br>

        for i = 1 : length(subject)<br>
        output = slshortfitBayesSmp(subject(i),initp(i,:),pscales(i,:),datapath);<br>
        end<br>
        toc<br>

      </code>

      <!-- SECTION -->
      <p><h7><a id="BLTL" class="anchor" href="#BLTL" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Bayes BLS tailed LLH</b></a></h7> </p>  

      <p>We manually searched for initial parameters that best graphically reproduced the data : </p>          

      <code class="code">  
        datapath = '~/Desktop/dataPsychophy/proj01_priorStrength';<br>
        o = slMakePredictionsWJM({'sub01'},[3 0.7 2.7 8 33 1e-2 32],
        'experiment','vonMisesPrior','dataPath',datapath,'BLSReadout')
      </code>

      <p>I fitted this model on a High Performance Cluster (Stanford's Sherlock) see details <a href="pages/fit_BayesLgTailBLS.html" class="class2"> here </a></p> to see how.

      <code class="code">      
        clear <br>          
        tic <br>
        datapath = '~/Desktop/dataPsychophy/proj01_priorStrength';<br>
        subject = {'sub01','sub02','sub03','sub04','sub07'};<br>        
        initp = [3 0.7 2.7 8 33 1e-2 32;
        1.5 2.77 4.5 15 33 1e-1 16;
        6 0.7 5 20 33 1e-2 16;
        2 0.7 2 8 66 1e-1 16;
        2 0 0 0 0 1e-1 16;
        2 0 0 8 8 1e-1 16;
        3 0 1 20 66 1e-2 16;
        1 0 0 0 33 0.1 8;
        4 0.1 1 8 33 0.1 8;
        2 0 0 8 33 0.2 8;
        4 0 0 8 33 0.1 8;
        1 0 1 4 33 0.1 16];<br>
        for i = 1 : length(subject)<br>
        o = slFitWJM(subject(i),initp(i,:),'pscaling',ones(1,7), 'experiment','vonMisesPrior','fminsearch','dataPath',datapath,'BLSReadout')<br>
        end<br>
        toc        
      </code>      

      <p><font color="red"> Note that after reviewer's comment on fitting convergence, I checked convergence parameters of fminsearch. Exitflags were zero for some of the initial parameters indicating that the algorithm stopped before reaching its default tolerance functions for the minimum change in the objective function and the model parameters (TolFun and TolX = 1e-4). I then rerun the fit with 10 times more iterations (now 2000*number of parameters instead of 200*number of parameters) and function evaluations (now 10*2000*number of parameters). </font></p>

      <p>Subjects concerned were all subjects</p>

      <!--SECTION-->
      <p><h7><a id="BLTLMAP" class="anchor" href="#BLTLMAP" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Bayes MAP tailed LLH </b></a></h7> </p>  

      <p>Initial parameters were set the same as for the Bayes with long tailed likelihood BLS Readout because both models made similar predictions. (The MAP readout shows a little more bimodality.). Based on this I would expect that model to perform marginally better than the model with BLS readout. </p>

      <p>We can look at the model predictions</p>

      <code class="code">
        datapath = '~/Desktop/dataPsychophy/proj01_priorStrength';
        [~,~,~,o] = slMakePredictionsWJM({'sub01'},[2.9938 0.6962 2.7277 8.0081 32.7443 0.01  33.5246],'experiment','vonMisesPrior','dataPath',datapath,'MAPReadout')
      </code>

      <p>I fitted this model on a High Performance Cluster (Stanford's Sherlock) see details <a href="pages/fit_BayesLgTailMAP.html" class="class2"> here </a></p> to see how. Here are the initial parameters
      used.

      <code class="code">     
        clear <br>          
        tic <br>        
        subject = {'sub01','sub02','sub03','sub04','sub05','sub06','sub07',
        'sub08','sub09','sub10','sub11','sub12'};<br>
        datapath = '~/Desktop/dataPsychophy/proj01_priorStrength/<br>
        initp = [3 0.7 2.7 8 33 1e-2 32;
        1.5 2.77 4.5 15 33 1e-1 16;
        6 0.7 5 20 33 1e-2 16;
        2 0.7 2 8 66 1e-1 16;
        2 0 0 0 0 1e-1 16;
        2 0 0 8 8 1e-1 16;
        3 0 1 20 66 1e-2 16;
        1 0 0 0 33 0.1 8;
        4 0.1 1 8 33 0.1 8;
        2 0 0 8 33 0.2 8;
        4 0 0 8 33 0.1 8;
        1 0 1 4 33 0.1 16];<br><br>
        for i = 1 : length(subject)<br>
        o = slFitWJM(subject(i),initp(i,:),
        'pscaling',ones(1,7),
        'experiment','vonMisesPrior','fminsearch','dataPath',datapath,'MAPReadout')<br>
        end <br>
        toc
      </code>

      <code class="code">            


        pscales = ones(12,7)
      </code>  

      <p>For a temptative fit on your local computer you can run this simpler version:</p>

      <code class="code">  
        initp = [3 0.7 2.7 8 33 1e-2 32]; <br>
        pscales = ones(1,7); <br>
        o = slFitWJM(subjects(i),initp(i,:),'pscaling',pscales(i,:),'MAPReadout',
        'experiment','vonMisesPrior','fminsearch','dataPath',datapath)        
      </code>        

      <p><font color="red"> Note that after reviewer's comment on fitting convergence, I checked convergence parameters of fminsearch. Exitflags were zero for some of the initial parameters indicating that the algorithm stopped before reaching its default tolerance functions for the minimum change in the objective function and the model parameters (TolFun and TolX = 1e-4). I then rerun the fit with 10 times more iterations (now 2000*number of parameters instead of 200*number of parameters) and function evaluations (now 10*2000*number of parameters). </font></p>

      <p>All subjects were concerned</p>

      <!-- SECTION -->
      <p><h7><a id="BMME" class="anchor" href="#BMME" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Bayes MAP motion energy model </b></a></h7> </p>  





      <!--SECTION-->
      <p><h7><a id="BLTP" class="anchor" href="#BLTP" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Bayes MAP tailed prior </b></a></h7> </p>  

      <p> We searched for initial parameters graphically : </p>

      <code class= "code">
        datapath = '~/Desktop/dataPsychophy/proj01_priorStrength'; <br>
        output = slshortfitBayesTailedPrior({'sub01'},[80 40 20 1.74 4.77 10.74 34.25 NaN 0.001 15 0],ones(1,11),datapath);<br>                 
      </code>

      <p> We used the same fit parameters as for the Basic Bayesian observer and set the initial tailed mixture parameter value to 0 : </p>

      <code class= "code">
       initp = [80 40 20 1.74 4.77 10.74 34.25 NaN 0.001 15 0; 
       101 70 22 1 3 9.74 34 NaN 0.0007 6.9 0;
       80 40 16 1.7 4.8 11 33 NaN 0.00039 17 0;
       79.3 38.9 9.19 1.7 4.8 11 33 NaN 0.00039 17 0;
       80 5 1 0 0 0 0 NaN 0.001 13.5 0;
       30 3 1 0.01 1.001 1.7 2 NaN 0.001 15 0;
       80 35 15 1.74 4.77 10.74 34.25 NaN 0.001 13.5 0;
       60 10 5 1.535 4.3425 10.62 40 NaN 0.00062 13.975 0;
       25 3 1.5 0.01 0.2 2 3.2 NaN 0.001 15 0;
       200 1 1 0.18 1 21.63 300.63 NaN 0.00104 5 0;
       25 3 1.5 0.06 0.2 2.1 3.4 NaN 0.001 15 0;
       5 2 1 0.01 1.00015 1.035 3 NaN 0.001 15 0];
     </code>

     <p>We then fitted the model to the data</p>

     <code class="code">        
      clear <br>          
      tic <br>
      subject = {'sub01','sub02','sub03','sub04','sub05','sub06','sub07',
      'sub08','sub09','sub10','sub11','sub12'};<br>
      datapath = '/Desktop/dataPsychophy/proj01_priorStrength/data'<br>
      pscales = ones(6,10) <br><br>

      for i = 1 : length(subject)<br>
      output = slshortfitBayesTailedPrior(subject(i),initp(i,:),pscales(i,:),datapath);<br>      
      end<br>
      toc<br>

    </code>

    <p><font color="red"> Note that after reviewer's comment on fitting convergence, I checked convergence parameters of fminsearch. Exitflags were zero for some of the initial parameters indicating that the algorithm stopped before reaching its default tolerance functions for the minimum change in the objective function and the model parameters (TolFun and TolX = 1e-4). I then rerun the fit with 10 times more iterations (now 2000*number of parameters instead of 200*number of parameters) and function evaluations (now 10*2000*number of parameters). </font></p>

    <p> Subjects concerned were subjects 2,7 </p>



    <p><h7><a id="BC" class="anchor" href="#BC" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Bayes cardinal </b></a></h7> </p>  

    <p>We used the same initial parameters as the Basic Bayesian model and set the initial cardinal prior strength parameter to 0. </p>

    <code class="code">
      initp = [80 40 20 1.74 4.77 10.74 34.25 0 0.001 15 NaN; 
      101 70 22 1 3 9.74 34 0 0.0007 6.9 NaN;
      80 40 16 1.7 4.8 11 33 0 0.00039 17 NaN;
      79.3 38.9 9.19 1.7 4.8 11 33 0 0.00039 17 NaN;
      80 5 1 0 0 0 0 0 0.001 13.5 NaN;
      30 3 1 0.01 1.001 1.7 2 0 0.001 15 NaN;
      80 35 15 1.74 4.77 10.74 34.25 0 0.001 13.5 NaN;
      60 10 5 1.535 4.3425 10.62 40 0 0.00062 13.975 NaN;
      25 3 1.5 0.01 0.2 2 3.2 0 0.001 15 NaN;
      200 1 1 0.18 1 21.63 300.63 0 0.00104 5 NaN;
      25 3 1.5 0.06 0.2 2.1 3.4 0 0.001 15 NaN;
      5 2 1 0.01 1.00015 1.035 3 0 0.001 15 NaN];
    </code>

    <p>We then fitted each subject trial data </p>

    <code class="code">
      datapath = '/Desktop/dataPsychophy/proj01_priorStrength/data'<br>
      subject = {'sub01','sub02','sub03','sub04','sub05','sub06','sub07',
      'sub08','sub09','sub10','sub11','sub12'};<br>
      pscales = ones(6,11)<br><br>

      for i = 1 : length(subs)<br>
      SLfitBayesianModel(subs(i),initp(i,:),
      'dataPathVM',datapath,'experiment','vonMisesPrior',
      'filename','datafit','MAPReadout','MaxLikelihoodFit',
      'fminsearch','filename',['data' subs{i}]);<br>
      end 
    </code>

    <p><font color="red"> Note that after reviewer's comment on fitting convergence, I checked convergence parameters of fminsearch. Exitflags were zero for some of the initial parameters indicating that the algorithm stopped before reaching its default tolerance functions for the minimum change in the objective function and the model parameters (TolFun and TolX = 1e-4). I then rerun the fit with 10 times more iterations (now 2000*number of parameters instead of 200*number of parameters) and function evaluations (now 10*2000*number of parameters). </font></p>

    <p> Subjects concerned were subjects 2 </p>


    <p><h7><a id="BSC" class="anchor" href="#BSC" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Bayes Sampling cardinal </b></a></h7> </p>  

    <p>We used the same initial parameters as the Bayesian sampling model and set the initial cardinal prior strength parameter to 0. </p>

    <code class="code">
      initp = [100 20 4 1.5 5 10 34 NaN 0.001 75 NaN;
      10 2.5 1.5 2 5 10 34 NaN 0.001 75 NaN;
      100 10 4 2 5 10 34 NaN 0.001 75 NaN;
      10. 4. 1.70 1.70 3.50 10. 34. NaN 0.001 75.00 NaN;
      40 4 1.70 0 0 0 0 NaN 0.001 75.00 NaN;
      15.00 4.00 2.00 0.50 3.50 10.00 34.00 NaN 0.001 75.00 NaN;
      35.00 7.00 2.00 0.50 2.00 7.00 34.00 NaN 0.001 75.00 NaN;
      4.00 2.00 1.00 0.50 1.50 2.00 2.50 NaN 0.001 75.00 NaN;
      30.00 4.00 2.00 0.50 1.00 6.00 6.00 NaN 0.001 75.00 NaN;
      200.00 3.00 1.60 0.01 1.00 21.63 300.63 NaN 0.001 5.00 NaN;
      30.00 4.00 2.00 0.20 1.00 3.00 10.00 NaN 0.001 75.00 NaN;
      5.00 2.00 1.50 0.15 1.00 3.00 10.00 NaN 0.001 75.00 NaN];
    </code>

    <p> and then fitted the model : </p>

    <code class="code">
      tic <br>
      subject = {'sub01','sub02','sub03','sub04','sub05','sub06','sub07',
      'sub08','sub09','sub10','sub11','sub12'};<br>
      datapath = '/Desktop/dataPsychophy/proj01_priorStrength/data'<br>
      pscales = ones(6,11);<br><br>

      for i = 1 : length(subject)<br>
      output = slshortfitBayesSmp(subject(i),initp(i,:),pscales(i,:),datapath);<br>
      end<br>
      toc<br><br>
    </code>


    <p><font color="red"> Note that after reviewer's comment on fitting convergence, I checked convergence parameters of fminsearch. Exitflags were zero for some of the initial parameters indicating that the algorithm stopped before reaching its default tolerance functions for the minimum change in the objective function and the model parameters (TolFun and TolX = 1e-4). I then rerun the fit with 10 times more iterations (now 2000*number of parameters instead of 200*number of parameters) and function evaluations (now 10*2000*number of parameters). </font></p>

    <p> Subjects concerned were subjects 2,4,12 </p>


    <p><h7><a id="BLTLP" class="anchor" href="#BLTLP" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>Bayes BLS tailed LLH </b></a></h7> </p>  


    <p><font color="red"> Note that after reviewer's comment on fitting convergence, I checked convergence parameters of fminsearch. Exitflags were zero for some of the initial parameters indicating that the algorithm stopped before reaching its default tolerance functions for the minimum change in the objective function and the model parameters (TolFun and TolX = 1e-4). I then rerun the fit with 10 times more iterations (now 2000*number of parameters instead of 200*number of parameters) and function evaluations (now 10*2000*number of parameters). </font></p>

    <p> Subjects concerned were all subjects </p>

    <!--SECTION-->
    <p><h7><a id="aicdiff" class="anchor" href="#BLTLMAP" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b>AIC difference</b></a></h7> </p>  

    <p> We computed the AIC difference between the model and the Switching observer (model - Switching AIC).  AIC difference > 0 means that Switching fits the data best otherwise it is worst. AIC diff = 0 means that we can't determine which model is the best. To draw the AIC difference for each model : </p>

    <code class="code">  
      <font color="green"> %Set path and models </font><br>
      path = '~/Desktop/dataPsychophy/proj01_priorStrength/modelfit/AIC/'; <br>
      model_ref = 'model_switching_MAP';<br> 
      models = {'model_CompDivPostorPrior',
      'model_Bayes_Sampling',
      'model_Bayes_Sampling_withCard',
      'model_Bayes_WJMtailedPrior',      
      'model_Bayes_WJM',
      'model_Bayes_MAP_withCard',
      'model_Bayes_MAP',     
      'model_Bayes_MAP_FatTailPrior'};<br>
      <font color="green"> Compute and plot mean AIC diff and CI over subjects per model </font><br>
      [AICsvsSw,semAICsvsSw,aicDiff] = slPlotModelsAICvsSwitchingAIC(model_ref,models,path); <br>
      [e,ci,m,s] = slMakeCI(aicDiff,0.95); 
    </code>  

    <!--SECTION-->
    <p><h7><a id="foc" class="anchor" href="#foc" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b> Fminsearch options for convergence</b></a></h7> </p>

    <p> We tested different settings with the Switching model to check whether we can maximize the quality and speed of convergence. Relaxing the Tolfun and tolx could permit quick convergence with possibly even less iterations. For example the default Tolfun is probably too strict (1e-4) if we care about changes in AIC of 2 units magnitude. Values of 1e-1 or 1e-2 might be more appropriate and time-efficient). It is more diffcult to know what TolX order of magnitude is relevant. The best is to test different order of magnitudes and see whether AIC magnitude changes by more than 2 units. </p>

    <center>
      <table>     
        <tr>
          <td>Optimization parameters </td><td>Iter</td><td>funEvals</td><td>TolFun</td><td>TolX</td>
        </tr>
        <tr>
          <td>Default </td><td>200 * # para</td><td>2000 * # para</td><td>1e-4</td><td>1e-4</td>
        </tr>
        <tr>
          <td>Increased iter - default TolX</td><td>2000 * # para</td><td>20 000 * # para</td><td>1e-4</td><td>1e-4</td>
        </tr>
        <tr>
          <td>Increased iter - strict TolX</td><td>2000 * # para</td><td>20 000 * # para</td><td>1e-4</td><td>1e-10</td>
        </tr>
        <tr>
          <td>Increased iter - no TolX</td><td>2000 * # para</td><td>20 000 * # para</td><td>1e-4</td><td>inf</td>
        </tr>
        <tr>
          <td>Increased iter - strict TolFun</td><td>2000 * # para</td><td>20 000 * # para</td><td>1e-10</td><td>1e-4</td>
        </tr>
      </table>
    </center>

    <!-- SECTION--> 
    <p><h7><a id="HI" class="anchor" href="#HI" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b> &nbsp &nbsp Increased Iter - No TolX : TolFun = 1e-4, TolX=inf MaxIter=2000*numFitP, MaxFunEvals=10*2000*numFitP</b></a></h7> </p> 

    <p> Using 10 times more iterations was stimulated by the fact that with the preceding 10 times less iterations some of the initial parameters sets did not convergence (exitflag=0). But keep in mind that relaxing the tolfun and tolx could permit quick convergence with possibly even less iterations. For example the default Tolfun is probably too strict (1e-4) if we care about changes in AIC of 2 units magnitude. Values of 1e-1 or 1e-2 might be more appropriate and time-efficient). It is more diffcult to know what TolX order of magnitude is relevant. The best is to test different order of magnitudes and see whether AIC magnitude changes by more than 2 units. </p>

    <p> We've tested stricter TolX which means convergence requires 1e6 times smaller changes in TolX (1e-10). </p>

    <p> We also tested no TolX which means convergence only depends on Tolfun. </p>

    <code class="code">

      <font color="green"> %Tols 1e-4, MaxIter 200*np MaxFun 2000*np </font><br>
      path = '~/Desktop/dataPsychophy/proj01_priorStrength/modelfit/AIC/model_CompDiv/';<br>
      [AICs0,allVars,sub] = slLoadSavedFitParams('AIC',path)<br><br>

      <font color="green"> %Tols 1e-4, MaxIter High : 2000*np MaxFun 20000*np</font><br>
      path = '~/Desktop/dataPsychophy/proj01_priorStrength/modelfit/AICtestSettings/defTolsHighIter/model_CompDiv/'; <br>
      [AICs1,allVars,sub] = slLoadSavedFitParams('AIC',path)<br><br>

      <font color="green"> %Strict tols 1e-10, MaxIter High </font><br>
      path = '~/Desktop/dataPsychophy/proj01_priorStrength/modelfit/AICtestSettings/lowTolFunAndX/model_CompDiv/';<br>
      [AICs2,allVars,sub] = slLoadSavedFitParams('AIC',path)<br><br>

      <font color="green"> %Strict tolFun 1e-10, TolX: 1e-4, MaxIter High </font><nr>
      path = '~/Desktop/dataPsychophy/proj01_priorStrength/modelfit/AICtestSettings/lowTolFunHighIter/model_CompDiv/';<br>
      [AICs3,allVars,sub] = slLoadSavedFitParams('AIC',path)<br><br>

      <font color="green"> %Strict TolX 1e-10, TolFun 1e-4, MaxIter High </font><br>
      path = '~/Desktop/dataPsychophy/proj01_priorStrength/modelfit/AICtestSettings/lowTolXHighIter/model_CompDiv/';<br>
      [AICs4,allVars,sub] = slLoadSavedFitParams('AIC',path)<br><br>

      <font color="green"> %No TolX inf, TolFun 1e-4, MaxIter high </font><br>
      path = '~/Desktop/dataPsychophy/proj01_priorStrength/modelfit/AICtestSettings/TolXInfHighIter/model_CompDiv/';<br>
      [AICs5,allVars,sub] = slLoadSavedFitParams('AIC',path)<br><br>

      <font color="green"> %Laxer Tols 1e-2, MaxIter High </font><br>
      path = '~/Desktop/dataPsychophy/proj01_priorStrength/modelfit/AICtestSettings/laxTolFunAndX/model_CompDiv/';<br>
      [AICs6,allVars,sub] = slLoadSavedFitParams('AIC',path)<br><br>

      <font color="green"> %plot each subject </font><br>
      for sub = 1 : 12 <nr>
      plot([AICs0(sub) AICs1(sub) AICs2(sub) AICs3(sub) AICs4(sub) AICs5(sub) AICs6(sub)],'.-') <nr>      
      end<br>

    </code>

    <p>Results :  It seems each subject data requires different convergence parameters.</p>

    <p><h7><a id="switchingfitp" class="anchor" href="#switchingfitp" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"><b> Table of Switching best fit parameters</b></a></h7> </p> 

    <code class="code">
      datafitpath = '~/Desktop/dataPsychophy/proj01_priorStrength/modelfit/AIC/';<br>
      [~,allvars,sub] = slLoadSavedFitParams('allVars',[datafitpath 'model_switching_MAP/'],'AIC');<br>
      nSubjects = length(allvars);<br>
      for i = 1 : nSubjects<br>
      fitP(i,:) = allvars(i).fitP<br>
      end<br>
      fitP = fitP(:,~isnan(fitP(1,:)));<br>
      fitP = num2cell(fitP);<br>
      header = {'Kl24','Kl12','Kl6','Kp80','Kp40','Kp20','Kp10','Prand','Km'};<br>
      headername = {'Subjects\Best parameters'};<br>
      rownames = num2cell([1 : nSubjects])';<br>
      mattable = [[headername header];[rownames fitP]];<br>
      cd ~/Desktop/<br>
      slconvMatCelltoCSV(mattable,'table')<br>
    </code>

    <p>Write in the terminal : </p>
    <code class="code">
      R<br>
      library(xtable)
      setwd('~/Desktop/')<br>
      dataset = read.csv('table.csv',header=TRUE,sep=",")<br>
      print(xtable(dataset), include.rownames=FALSE)<br>
    </code>

    <p>Fine tune, copy the printed latex output in "latexit" to plot the table and save in the file format you want.</p>

    <p>The probability</p>
    <code class="code">
      slplotProbaSwitchEachSub(cell2mat(fitP)
    </code>

  </section>
</div>



<!-- FOOTER  -->
<div id="footer_wrap" class="outer">
  <footer class="inner">
    <p class="copyright">Projinference maintained by <a href="https://github.com/steevelaquitaine">steevelaquitaine</a></p>
    <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
  </footer>
</div>

</body>
</html>
