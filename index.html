<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Project inference : Design an experiment which requires human subjects to do inference, analyse, mine and model their behavior to understand whether/how they do inference ?">
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">
    <link rel="stylesheet" href="fonts/Serif/cmun-serif.css" />
    <!--<link rel="stylesheet" href="fonts/Serif-Slanted/cmun-serif-slanted.css" />-->
  </head>

  <body>
    
    <title>Project inference</title>
    
    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/steevelaquitaine/projInference">View on GitHub</a>
          <a id="project_author" href="http://steevelaquitaine.blogspot.com"> Steeve laquitaine </a>
        </header>
    </div>

    <!--TITLE-->
    <div id="proj_title_wrap" class="outer">
        <!--<header class="inner">-->
        <section id="proj_title" class="inner">
        <h1 id="proj_title"> How do we make visual inference ? </h1>
    </div>

    <!--Table of contents-->
    <div id="Table_of_content_wrap" class="outer">
      <section id="table_of_content" class="inner">
        <h6> Table of Content </h6>
        <a href="#Approach-to-inference"> Approach to inference <br>
        <a href="#Design-an-inference-experiment"> Design an inference experiment <br>
        <a href="#Estimation-error-depends-on-evidence-strength-and-on-motion-direction-statistics"> Estimation error depends on evidence strength...and on motion direction statistics <br>
        <a href="#Why-is-estimates-relationship-to-physical-directions-nonlinear-?"> Why is estimates relationship to physical directions nonlinear? <br>
        <a href="#Humans-use-environment-statistics"> Humans use environment statistics <br>
        <a href="#Switching-between-prior-and-evidence-outperform-the-Bayesian-observer"> Switching between prior and evidence outperforms the Bayesian observer <br>
        <a href="#Subjects-represented-prior-strengths-accurately"> Subjects represented prior strengths accurately <br>
        <a href="#Why-other-plausible-Bayesian-observers-fail-to-switching"> Why other plausible Bayesian observers fail to switching <br>
        <a href="#Eye-movement"> Eye movement <br>
      </section>
    </div>
    
    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
          
        <h6><a id="Approaches-to-inference" class="anchor" href="#Approaches-to-inference" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Approaches to inference.</h3>  
        <p> Three main theories have been proposed as to how humans solve inference problems. 1) Humans might be rational : they use optimal statistical solutions to inference problems or 2) 
        irrational and produce maladaptive solutions to inference problems or 3) they use heuristics computational shortcuts that approximate optimal solutions. This fits in with Herbert 
        Simon theory of bounded rationality according to which humans use satisficing solutions (sufficient and satisfying) (Gigerenzer, Psychological 
        review 1996)</p>
  
        <h6><a id="Design-an-inference-experiment" class="anchor" href="#Design-an-inference-experiment" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Designing an inference experiment.</h3>
        <p>We designed a motion direction estimation experiment in which humans were asked to estimate the motion direction of noisy stimuli on a computer screen. In this experiment statistical optimality can be achieved by combining noisy evidence of the motion with knowledge of the motion direction statistics learnt over motion stimulus history using Bayesian inference</p>
        <center><img src="images/experiment.png"></center>
        
        <h6><a id="Estimation-error-depends-on-evidence-strength-and-on-motion-direction-statistics" class="anchor" href="#Estimation-error-depends-on-evidence-strength" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Estimation error depends on evidence strength ....and on motion direction statistics</h3>
        <p>Estimate versus displayed motion directions for different motion noise (from 6% to 24% motion coherence).</p>
        
        <!--figure-->
        <center><img src="images/BayesHypo.png"></center>      
        
        <!--figure-->
        <center><img src="images/BayesFit_meanvar.png" style="width: 75%; height: 75%"/></center>   
        
        <!--figure-->
        <center><img src="images/BayesFit_dis.png"></center>   
        
        <!--figure-->
        <center><img src="images/SwitchingAndFits.png"></center>  
        
        <!--figure-->
        <center><img src="images/AICsFailureModes.png.png"></center>
        
        <!--figure-->
        <center><img src="images/RecencyBias.png" style="width: 50%; height: 50%"/></center>
        
        
        <h6><a id="#Why-is-estimates-relationship-to-physical-directions-nonlinear-?" class="anchor" href="#Why-is-estimates-relationship-to-physical-directions-nonlinear-?" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Why is estimates relationship to physical directions nonlinear?</h3>
        <p>The bias was also the largest for directions displayed the nearest to the prior mean and the smallest on the 
        opposite side of the prior, producing a nonlinear relationship between displayed and estimated directions. 
        This effect is due to the circularity of the space: the average bias become smaller when directions are displayed 
        further from the prior because the evidence is more and more likely to be pulled from both sides of the prior which 
        reduces the average bias. This decreasing bias with increasing distance effect effectively disappears in a linear 
        space as the evidence is always pulled from one side of the prior.
        
        <p>The variability was also the lowest for directions displayed the nearest to the prior mean and the largest 
        on the opposite side of the prior. This effect was due to the same reason that the average bias decreased further 
        from the prior: evidence were more often pulled from both sides of the prior which increased estimate dispersion.<p>
        
        <!--Code-->
        <code class="code">
        >> slsimulateBayesianModelEstimateSpace(5:20:360); 
        </code>
        
        <!--figure-->
        <center><img src="images/BiasAndVarInCircularVsLinearSpace.png"></center>
  
        <!--Head-->
        <h6><a id="Humans use environment's statistics" class="anchor" href="#Humans-use-environment-statistics" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Humans use environment statistics</h3>
        <p>A Bayesian observer that uses the statistical distribution of motion directions fit the data beter than a maximum likelihood observer that only uses sensory likelihood. This indicates that subjects incoporated and ued prior 
        knowledge about environment statistics for inference and did not solely rely on the sensory evidence. </p>
        
        <!--code  -->
        <code class="code">
              >> bo = [77182.68 74175.23 84145.32 46451.09 61913.16 75357.9 54584.24 62731.75 84927.68 62633.63 63233.81 66099.47]; <br>
              >> mlo = [100803.6 92739.7 110810.02 56504.8 68159.3 88925.5 68253.5 68253.5 101627.7 71161.2 76223.3 76223.3]; <br>
              >> [e, ci, m, s]= slMakeCI(bo, 0.95) <br>
              >> [e, ci, m, s] = slMakeCI(mlo, 0.95)
        </code>
  
        <p> This is even clearer when loooking at the AIC difference between the two models, averaged over subjects </p>
        <!--code  -->
        <code class="code">
            >> [e,ci,m,s] = slMakeCI(mlo - bo,0.95);
        </code>
  
        <!--table-->
        <!--<table style="width:30%">-->
        <!--<caption> Bayesian observer better fit data than a maximum likelihood observer (lower Akaike Information criterion (AIC)) </caption>-->
        <!--Table titles-->
        <!--<tr>-->
        <!--  <th>Models</th><th>sub01</th><th>sub02</th><th>sub03</th><th>sub04</th><th>sub05</th><th>sub06</th><th>sub07</th><th>sub08</th><th>sub09</th><th>sub10</th><th>sub11</th><th>sub12</th>-->
        <!--</tr>-->
        <!--row 1-->
        <!--<tr>-->
        <!--  <td>Bayesian observer </td><td> 77182.68 </td><td> 74175.23 </td><td> 84145.32 </td><td> 46451.09 </td><td> 61913.16 </td><td> 75357.9 </td><td> 54584.24 </td><td> 62731.75 </td><td> 84927.68 </td><td> 62633.63 </td><td> 63233.81 </td><td> 66099.47 </td>-->
        <!--</tr>-->
        <!--row 2-->
        <!--<tr>-->
        <!--  <td>Maximum likelihood observer </td><td> 100803.6 </td><td> 92739.7 </td><td> 110810.02 </td><td> 56504.8 </td><td> 68159.3 </td><td> 88925.5 </td><td> 68253.5 </td><td> 68253.5 </td><td> 101627.7 </td><td> 71161.2 </td><td> 76223.3 </td><td> 76223.3 </td> -->
        <!--</tr>-->
        <!--</table>-->
       <!--Head-->
  
        <h6><a id="Switching-between-prior-and-evidence-outperform-the-Bayesian-observer" class="anchor" href="#Switching-between-prior-and-evidence-outperform-the-Bayesian-observer" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Switching between prior and evidence outperforms the Bayesian observer</h3> 
  
        <!--code  -->
        <code class="code">
          <!--<div style="background-color:#f2f2f2; color:black; line-height:0.8; padding:10px;">   -->
             >> model_ref = 'model_CompDiv'; <br>
             >> models = {'model_Bayes_MAP'}; <br>
             >> path = '/ Volumes/ DroboBKUP/ data/ dataPsychophy/ proj01_priorStrength/ modelfit/ AIC/'; <br>
             >> [~, ~, aicDiff01] = slPlotModelsAICvsSwitchingAIC(model_ref, models, path); <br>
             >> figure('color','w') <br>
             >> SLdrawBar(aicDiff01, 1:12, 1:12, 'facecolor', [.5 .5 .5]);
        </code>
        
        <!--figure-->
        <center><img src="images/AICbayesVsSwitch.png" style="width: 50%; height: 50%"/></center>   
        
        
        
        
        
        <!--section-->
        <h6><a id="Subjects-represented-prior-strengths-accurately" class="anchor" href="#Subjects-represented-prior-strengths-accurately" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Subjects represented prior strengths accurately</h3> 
        
        <p> We examined the fit parameters used to model subject prior strengths with the switching observer to determine whether subjects had accurate representations 
        of the spread of the motion direction statistical distribution over trials (experimental prior). We compared the subjective prior strengths prescribed by 
        the switching observer with those predicted by the Basic Bayesian observer. </p>
        
        <!--figure here median prior strengths-->
        
        <p> We tested whether the switching observers predicted strength were statistically more accurate than the strengths predicted by the Bayesian observer.
        Most prior strengths were not normally distributed across subjects (lilliest, most p < 0.05) : </p>
        
        <!--Code-->
        <code class="code">
          >> cd('~/proj/steeve/projInference/data/') <br>
          >> [~,~, data] = slcsvRead('data_PriorStrngths.csv'); <br>
          >> [Pbo,Psw,subBOstd,subswstd] = slIsPriorStrgDisNormal(data);
        </code>
        
        <p> So we compared the median over subjects of the four subjective prior strength parameters fitted by the switching observer to 
        each subject’s data (Fig. 6b) to veridical strength  and found that although the switching observer’s median fitted prior 
        over subjects were significantly weaker than the 80º and 40º veridical priors (W = 7, p < 0.01 and W = 0, p < 0.01 
        respectively, one-sample Wilcoxon test), the switching observer’s fitted prior standard deviations for the 20º and 10º 
        priors did not significantly differ from the veridical prior standard deviations (W=17, p=0.09 and W=27, p=0.38 for the 
        20 and 10 deg priors, one-sample Wilcoxon test). In contrast, the Basic Bayesian observer’s median fitted priors over 
        subjects were all significantly weaker than the veridical priors (W=1, W=1, W=3, W=2, all p<0.01, for the 80, 40, 20 
        and 10 deg priors respectively, one-sample Wilcoxon test) which would suggest that the observers were unable to make accurate 
        estimates of the prior distribution. </p>
        
        <!--Code-->
        <code class="code">  
            >> [pbo,psw,Hbo,Hsw,wbo,wsw] = slcompBoandSwPriorStrgToExp(subBOstd,subswstd,subExpstd);
        </code>   
        
        
        
        
        
        
        
       <!--section-->
        <h6><a id="Why-other-plausible-Bayesian-observers-fail-to-switching" class="anchor" href="#Why-other-plausible-Bayesian-observers-fail-to-switching" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Why other plausible Bayesian observers fail to switching</h3> 
      
        - a basic Bayesian model [Stocker 2006; Girshick 2011] <br>
        - a sampling Bayesian model [Pouget 2011] <br>
        - a basic Bayesian model with cardinal priors [Stocker 2006; Girshick 2011]<br>
        - a basic Bayesian model with likelihood computed from stimulus components [Stocker 2006; Girshick 2011]<br>
        - Hierarchical Bayesian inference [Mumford 2003]<br>
      
        <!--code-->
        <code class="code">
             >> model_ref = 'model_CompDiv'; <br> 
             >> models = {'model_Bayes_Sampling', 'model_Bayes_Sampling_withCard', 'model_Bayes_WJMtailedPrior', ... <br> 
             'model_Bayes_WJM', 'model_Bayes_MAP_withCard', 'model_Bayes_MAP', 'model_Bayes_MAP_FatTailPrior'}; <br> 
             >> path = '/Volumes/ DroboBKUP/ data/ dataPsychophy/ proj01_priorStrength/ modelfit/ AIC/ '; <br> 
             >> [AICsvsSw, semAICsvsSw, aicDiff] = slPlotModelsAICvsSwitchingAIC(model_ref, models, path); 
        </code>
        
        
        <!--Figure-->
        <center><img src="images/WhyBayesianObserversFail.png" style="width: 100%; height: 100%"/></center>
        
        <p> We examined how well other Bayesian observers fit the data compared to the switching observer
        
        <!--code  -->
        <code class="code">
          <!--<div style="background-color:#f2f2f2; color:black; line-height:0.8; padding:10px;">   -->
           >> model_ref = 'model_CompDiv'; <br>
           >> models = {'model_Bayes_Sampling', 'model_Bayes_Sampling_withCard', 'model_Bayes_WJMtailedPrior', ... <br> 
           'model_Bayes_WJM', 'model_Bayes_MAP_withCard', 'model_Bayes_MAP', 'model_Bayes_MAP_FatTailPrior' }; <br>
           >> path = '/Volumes/ DroboBKUP/ data/ dataPsychophy/ proj01_priorStrength/ modelfit/ AIC/ '; <br>
           >> [AICsvsSw, semAICsvsSw, aicDiff] = slPlotModelsAICvsSwitchingAIC(model_ref, models, path); 
        </code>
        
        <!--code  -->
        <code class="code">
              >> model_ref = 'model_CompDiv'; <br>
              >> models = {'model_Bayes_Sampling', 'model_Bayes_Sampling_withCard', 'model_Bayes_WJMtailedPrior', ... <br>
              'model_Bayes_WJM', 'model_Bayes_MAP_withCard', 'model_Bayes_MAP', 'model_Bayes_MAP_FatTailPrior'}; <br>
              >> path = '/Volumes/ DroboBKUP/ data/ dataPsychophy/ proj01_priorStrength/ modelfit/ AIC/'; <br>
              >> [AICsvsSw, semAICsvsSw, aicDiff] = slPlotModelsAICvsSwitchingAIC(model_ref, models, path);
        </code>
        
        <p> We also examined the number of subjects for which switching outperformed the other Bayesian observers </p>
        
        <!--code  -->
        <code class="code">
           >> cd('~/proj/ steeve/ projInference/ data/) <br>
           >> [rowheader, colheader, data] = slcsvRead('modelfitData.csv'); <br>
           >> [nRefWins, nNoWin, nRefLoses] = slPlotPropSubSwitchingVsBayesModels(rowheader, colheader, data, ... <br>
           'Switching observer')
        </code>
  
  
  
  
        <!--section-->
        <h6><a id="Eye-movement" class="anchor" href="#Eye movement" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Eye movement</h3> 
        
        <p> We examined whether subjects eye positions changed between prior conditions.  </p>
        
        <!--code  -->
        <code class="code">
           >> datapath = '~/../myProjData/'; <br>
           >> [eyedatabank,output] = SLanalysesEyeMvt({'sub01'},'dataPath', datapath, 'AnovaEyeMvt', 'plotEyeMvtStats', 'filename', 'test');
        </code>
        
        <p> The eye positions averaged over subjects did not significantly change between priors </p>
        
        <!--code  -->
        <!--<section class="code">-->
        <!--   <p> >>   cd ~/.../ projInference/ data; <br>-->
        <!--   >>   [rowheader, colheader, data] = slcsvRead('data_meanEyePosition.csv'); <br>-->
        <!--   >>   [m, ci, condition] = sleyePosMeanAndCIByPrior(data); </p>-->
        <!--</section>-->
        <code>
           >>   cd ~/.../ projInference/ data; <br>
           >>   [rowheader, colheader, data] = slcsvRead('data_meanEyePosition.csv'); <br>
           >>   [m, ci, condition] = sleyePosMeanAndCIByPrior(data);
        </code>

      <!--End Main Content-->
      </section>
    </div>
    
    
    
    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Projinference maintained by <a href="https://github.com/steevelaquitaine">steevelaquitaine</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

  </body>
</html>
