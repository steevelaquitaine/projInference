<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Project inference : Design an experiment which requires human subjects to do inference, analyse, mine and model their behavior to understand whether/how they do inference ?">
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">
    <link rel="stylesheet" href="fonts/Serif/cmun-serif.css" />

    <!--Mathematics with MathJax-->
    <script type="text/x-mathjax-config">      
      MathJax.Hub.Config({
          extensions: ["tex2jax.js"],
          jax: ["input/TeX", "output/HTML-CSS"],
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
              processEscapes: true
          },
          "HTML-CSS": { 
            availableFonts: ["STIX"],
          }
      });
    </script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML">
    </script>  

  </head>

  <body>
    
    <title>How do we make visual inference</title>
    
    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/steevelaquitaine/projInference">Github</a>
          <a id="project_author" href="http://steevelaquitaine.blogspot.com">Steeve laquitaine </a>
        </header>
    </div>

    <!--TITLE-->
    <div id="proj_title_wrap" class="outer">
        <header class="inner">
        <section id="proj_title" class="inner">
        <h1 id="proj_title"> How do we make visual inference ? </h1>
    </div>
    
    <!--Table of contents    -->
     <div id="Table_of_content_wrap" class="outer">
      <section id="table_of_content" class="inner">
        <h5 id="top"> TABLE OF CONTENTS </h5>
        <h7><a href="#Inference"> INFERENCE <br></h7>
        <h7><a href="#Example-of-an-inference-task">EXAMPLE OF AN INFERENCE TASK <br></h7>
        <h7><a href="#Data"> DATA <br></h7>
        <h7><a href="#Task-noise-&-statistics-affect-estimation">EFFECT OF TASK NOISE & STATISTICS <br></h7>
        <h7><a href="#Humans-approximate-optimality">HUMANS APPROXIMATE OPTIMALITY <br></h7>
        <h7><a href="#Humans-quickly-learn-complex-statistics">HUMANS QUICKLY LEARN COMPLEX STATISTICS <br></h7>
        <h7><a href="#Eye-movement"> EYE POSITIONS <br></h7>
        <h7><a href="#Generalization-to-another-task">GENERALIZATION TO ANOTHER TASK <br></h7>
      </section>
    </div>
    
    
    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
          
        <h7><a id="Inference" class="anchor" href="#Inference" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top">INFERENCE</a></h7>  
        <p> Three main theories have been proposed as to how humans solve inference problems. 1) Humans might be rational : they use optimal statistical solutions to inference problems or 2) 
        irrational and produce maladaptive solutions to inference problems or 3) they use heuristics computational shortcuts that approximate optimal solutions. This fits in with Herbert 
        Simon theory of bounded rationality according to which humans use satisficing solutions (sufficient and satisfying) (Gigerenzer, Psychological 
        review 1996)</p>

        <h7><a id="Example-of-an-inference-task" class="anchor" href="#Example-of-an-inference-task" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"> EXAMPLE OF AN INFERENCE TASK </a></h7>   
      
        <p> We used a stimulus that has been used extensively in the psychophysics literature and that allows to manipulate sensory noise and also subjects priors : the random dot motion stimulus 
        This stimulus is composed of signal dots moving in the same (coherent) directions and noise dots that move in random dots and render the estimation of the motion direction
        difficult. We manipulated the difficulty of estimation by changing the proportion of dots moving coherently (6, 12 or 24%), thus the signal to noise ratio of the motion as follows : </p>
        
        <!--video-->
        <div id="videoal" align ="center" style="padding:10px">
            <div class="video">
                <video controls autoplay>
                    <source src="images/motioncoh06.mp4" type="video/mp4">
                </video>
            </div>
            <div class="video">
               <video controls autoplay>
                    <source src="images/motioncoh12.mp4" type="video/mp4">
               </video>
            </div>
            <div class="video">
               <video controls autoplay>
                    <source src="images/motioncoh24.mp4" type="video/mp4">
               </video>
            </div>
        </div>
        
        <p>We designed a motion direction estimation experiment in which humans were asked to estimate the motion direction of the noisy motions on 
        <center><img src="images/exp.png" style="width: 50%; height: 50%"></center>
        
        <p>In this experiment statistical optimality can be achieved by combining noisy evidence of the motion with knowledge of the motion 
        direction statistics learnt over motion stimulus history using Bayesian inference</p>
        <!--figure-->
        <center><img src="images/BayesHypo.png" style="width: 75%; height: 75%"></center>      
        


        <!--Section-->
        <h7><a id="Data" class="anchor" href="#lars" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"> DATA </a></h7>   

        <p> Number of trials per subjects : sub01 : 5367 .... (insert table here) </p>

        <p> You can access data files : <a href="data"> here </a></p>
      



        <!--Section-->
        <h7><a id="Task-noise-&-statistics-affect-estimation" class="anchor" href="#Task-noise-&-statistics-affect-estimation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top">EFFECT OF TASK NOISE & STATISTICS</a></h7>
        <p> We looked at subjects average estimates for each displayed motion directions, for different level of noise in the stimulus (from 6% to 24% motion coherence) and 
        different distributions of the motion direction (distribution standard deviation of 80º, 40º, 20º and 10º with fixed mean at 225º).</p>
        
        <!--Code-->
        <code class="code">
            >> datapath = slgetdatapath('lab'); <br><br>

            >> output = SLfitBayesianModel({'sub01','sub02',... <br>
                'sub03','sub04','sub05','sub06','sub07','sub08','sub09','sub10',... <br>
                'sub11','sub12'},[NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN],... <br>
                'dataPathVM',datapath,'experiment','vonMisesPrior',... <br>
                'MAPReadout','modelPredictions','withData',... <br>
                'directoryFitParameter','../modelfit/AIC/',... <br>
                'filename','fig03_04');
        </code>
    
        <p>The Bayesian observer predicted subject estimate mean and variability very well...</p>
        <!--figure-->
        <center><img src="images/BayesFit_meanvar.png" style="width: 50%; height: 50%"/></center>   
        
        <p> <strong> Subjects were strongly biased toward the prior mean </strong> (most likely motion direction at 225 deg). The strongest prior when 
        the motion was the weakest produced biases between (You can select the plot of mean estimate versus displayed directions for the 
        strongest prior (brown data point) at the weakest coherence (most right panel) and run the following code to extract the plot values
        and calculate the min and max average biases) </p>
        
        <!--Code-->
        <code class="code">
        
          %locate conditions
          >> p10_c6 = output.uniqCond(:,1)==10 & output.uniqCond(:,2)==0.06;
          >> dir_p10_c6 = output.uniqCond(p10_c6,3);
          
          %calculate biases
          >> e = round(output.meanData(p10_c6,:));
          >> nSub = size(output.meandata);
          >> for s = 1 : nSub
          >>    biases(:,s) = SLvectors2signedAngle(e(:,s),dir_p10_c6,'polar')
          >> end
          
          % normalize biases such that biases toward/away from the prior are positive/negative 
          >> norm_bias = [biases(dir_p10_c6<225,:) ; biases(dir_p10_c6>225,:).*repmat(-1,size(biases(dir_p10_c6>225,:)))];
          
          %get stats
          >> nDir = length(dir_p10_c6);
          >> for d_i = 1 : nDir-1
          >>    [~,ci,m] = slMakeCI(norm_bias(d_i,:),.95);
          >>     ciOvS(d_i,:) = ci;
          >>     meanBiasBydirOvS(d_i) = m;
          >> end

          %min subject average bias across directions and its confidence intervals <br>
          >> minBiasOvSByDir = unique(meanBiasBydirOvS(find(meanBiasBydirOvS==min(abs(meanBiasBydirOvS)))))
          >> CIminBiasAll = ciOvS(find(minBiasOvSByDir == meanBiasBydirOvS),:); <br><br>
          
          %Average bias over subjects and confidence intervals <br>
          >> [~,ciMeanBiasOvS,meanBiasOvS] = slMakeCI(nanmean(norm_bias,1),.95)
          
          %max subject average bias across directions and its confidence intervals
          >> maxBiasOvSByDir = unique(meanBiasBydirOvS(find(meanBiasBydirOvS==max(abs(meanBiasBydirOvS)))))
          >> CImaxBiasAll = ciOvS(find(maxBiasOvSByDir == meanBiasBydirOvS),:); <br><br>
          
          % We calculate bias at the prior mean 225 deg separately because they are always <br>
          % away from the prior mean when non null negative (clockwise) or positive <br>
          % (counterclockwise). We interprete this bias as noise. <br>
          meanBiasOvSatPrior = mean(biases(dir_p10_c6==225,:),2);
          
        </code>
        
                  
        <h7><a id="Humans-approximate-optimality" class="anchor" href="#Humans-approximate-optimality" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top">HUMANS APPROXIMATE OPTIMALITY</a></h7>  
        
        <p> ... But it failed to explain the subjects' estimates distribution pattern formed over trials: where the model predicts unimodal distributions, 
        subjects estimate distribution were clearly bimodal.</p>
        <!--figure-->
        <center><img src="images/BayesFit_dis.png" style="width: 55%; height: 55%"/></center>   
        
        <p>The behavior rather posits for an model in which people do not integrate their prior and sensory likelihood in a posterior that 
        estimate that lie in between the two but rather switch between the two representations. </p>
        <!--figure-->
        <center><img src="images/SwitchingAndFits.png" style="width: 75%; height: 75%"/></center>  
        
        <p>We tested other plausible Bayesian observers but all failed to explain the data better than the switching observer </p>
        <!--figure-->
        <center><img src="images/AICsFailureModes.png" style="width: 35%; height: 35%"/></center>  
        
        <p>We also tested whether subject did not learn priors but simply relied on the previous trial displayed motion direction 
        (a recency strategy). However the data clearly indicate that subjects were biased toward the prior mean and not the previous 
        trial and that the stronger the prior and the stronger their bias toward the prior mean, indicating that subjects learn and 
        used the prior mean and strengths. </p>
        <!--figure-->
        <center><img src="images/RecencyBias.png" style="width: 50%; height: 50%"/></center>
        
        <p>The bias was also the largest for directions displayed the nearest to the prior mean and the smallest on the 
        opposite side of the prior, producing a nonlinear relationship between displayed and estimated directions. 
        This effect is due to the circularity of the space: the average bias become smaller when directions are displayed 
        further from the prior because the evidence is more and more likely to be pulled from both sides of the prior which 
        reduces the average bias. This decreasing bias with increasing distance effect effectively disappears in a linear 
        space as the evidence is always pulled from one side of the prior.
        
        <p>The variability was also the lowest for directions displayed the nearest to the prior mean and the largest 
        on the opposite side of the prior. This effect was due to the same reason that the average bias decreased further 
        from the prior: evidence were more often pulled from both sides of the prior which increased estimate dispersion.<p>
        
        <!--Code-->
        <code class="code">
        >> slsimulateBayesianModelEstimateSpace(5:20:360); 
        </code>
        
        <!--figure-->
        <center><img src="images/BiasAndVarInCircularVsLinearSpace.png"></center>
  
        <!--Head-->
        <h7><a id="Humans-quickly-learn-complex-statistics" class="anchor" href="#Humans-quickly-learn-complex-statistics" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top">HUMANS QUICKLY LEARN COMPLEX STATISTICS</a></h7>
        <p>A Bayesian observer that uses the statistical distribution of motion directions fit the data beter than a maximum likelihood observer that only uses sensory likelihood. This indicates that subjects incoporated and ued prior 
        knowledge about environment statistics for inference and did not solely rely on the sensory evidence. </p>
        
        <!--code  -->
        <code class="code">
              >> bo = [77182.68 74175.23 84145.32 46451.09 61913.16 75357.9 54584.24 62731.75 84927.68 62633.63 63233.81 66099.47]; <br><br>
              
              >> mlo = [100803.6 92739.7 110810.02 56504.8 68159.3 88925.5 68253.5 68253.5 101627.7 71161.2 76223.3 76223.3]; <br><br>
              
              >> [e,ci,m,s] = slMakeCI(bo,0.95) <br><br>
              
              >> [e,ci,m,s] = slMakeCI(mlo,0.95)
        </code>
  
        <p> This is even clearer when loooking at the AIC difference between the two models, averaged over subjects </p>
        <!--code  -->
        <code class="code">
            >> [e,ci,m,s] = slMakeCI(mlo - bo,0.95);
        </code>
  
        <!--code  -->
        <code class="code">
             >> model_ref = 'model_CompDiv'; <br><br>
             
             >> models = {'model_Bayes_MAP'}; <br><br>
             
             >> path = '/Volumes/DroboBKUP/data/dataPsychophy/... <br>
                        &nbsp &nbsp &nbsp &nbsp &nbsp proj01_priorStrength/modelfit/AIC/'; <br>
             
             >> [~,~,aicDiff01] = slPlotModelsAICvsSwitchingAIC(model_ref,models,path); <br><br>

             >> figure('color','w') ; SLdrawBar(aicDiff01,1:12,1:12,'facecolor',[.5 .5 .5]);
        </code>
        
        <!--figure-->
        <center><img src="images/AICbayesVsSwitch.png" style="width: 50%; height: 50%"/></center>   
        
        
        <!--section-->
        <p> We examined the fit parameters used to model subject prior strengths with the switching observer to determine whether subjects had accurate representations 
        of the spread of the motion direction statistical distribution over trials (experimental prior). We compared the subjective prior strengths prescribed by 
        the switching observer with those predicted by the Basic Bayesian observer. </p>
        
        <!--figure here median prior strengths-->

        <p> We tested whether the switching observers predicted strength were statistically more accurate than the strengths predicted by the Bayesian observer.
        Most prior strengths were not normally distributed across subjects (lilliest, most p < 0.05) : </p>
        
        <!--Code-->
        <code class="code">
          >> cd('~/proj/steeve/projInference/data/') <br><br>
          
          >> [~,~,data] = slcsvRead('data_PriorStrngths.csv'); <br><br>
          
          >> [Pbo,Psw,subBOstd,subswstd] = slIsPriorStrgDisNormal(data);
        </code>
        
        <p> So we compared the median over subjects of the four subjective prior strength parameters fitted by the switching observer to 
        each subject’s data (Fig. 6b) to veridical strength  and found that although the switching observer’s median fitted prior 
        over subjects were significantly weaker than the 80º and 40º veridical priors (W = 7, p < 0.01 and W = 0, p < 0.01 
        respectively, one-sample Wilcoxon test), the switching observer’s fitted prior standard deviations for the 20º and 10º 
        priors did not significantly differ from the veridical prior standard deviations (W=17, p=0.09 and W=27, p=0.38 for the 
        20 and 10 deg priors, one-sample Wilcoxon test). In contrast, the Basic Bayesian observer’s median fitted priors over 
        subjects were all significantly weaker than the veridical priors (W=1, W=1, W=3, W=2, all p<0.01, for the 80, 40, 20 
        and 10 deg priors respectively, one-sample Wilcoxon test) which would suggest that the observers were unable to make accurate 
        estimates of the prior distribution. </p>
        
        <!--Code-->
        <code class="code">  
            >> [pbo,psw,Hbo,Hsw,wbo,wsw] = slcompBoandSwPriorStrgToExp(subBOstd,...<br>
                                             &nbsp &nbsp &nbsp &nbsp &nbsp subswstd,subExpstd);
        </code>   
        
        <p> We tested various other plausible Bayesian observers, relaxing certain assumptions about how subject brain might represent the 
        likelihood and priors, or how their brain might read out those information. We were inspired by models that have been used by past studies
        to explain other aspects of perception :
        - a basic Bayesian model [Stocker 2006; Girshick 2011] <br>
        - a sampling Bayesian model [Pouget 2011] <br>
        - a basic Bayesian model with cardinal priors [Stocker 2006; Girshick 2011]<br>
        - a basic Bayesian model with likelihood computed from stimulus components [Stocker 2006; Girshick 2011]<br>
        - Hierarchical Bayesian inference [Mumford 2003]<br>
        </p>
      
        <!--code-->
        <code class="code">
             >> model_ref = 'model_CompDiv'; <br> 
             
             >> models = {'model_Bayes_Sampling','model_Bayes_Sampling_withCard',...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp             'model_Bayes_WJMtailedPrior','model_Bayes_WJM',...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp             'model_Bayes_MAP_withCard',...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp             'model_Bayes_MAP','model_Bayes_MAP_FatTailPrior'}; <br><br>
                           
             >> path = '~/data/dataPsychophy/proj01_priorStrength/modelfit/AIC/'; <br><br>
             
             >> [AICsvsSw,semAICsvsSw,aicDiff] = slPlotModelsAICvsSwitchingAIC(model_ref,...<br>
            &nbsp &nbsp &nbsp &nbsp &nbsp                                   models,path); 
        </code>
        
        
        <!--Figure-->
        <center><img src="images/WhyBayesianObserversFail.png" style="width: 100%; height: 100%"/></center>
        
        <p> We examined how well other Bayesian observers fit the data compared to the switching observer
        
        <!--code  -->
        <code class="code">
           >> model_ref = 'model_CompDiv'; <br><br>
           
           >> models = {'model_Bayes_Sampling','model_Bayes_Sampling_withCard',...<br>
           &nbsp &nbsp &nbsp &nbsp &nbsp               'model_Bayes_WJMtailedPrior','model_Bayes_WJM',...<br>
           &nbsp &nbsp &nbsp &nbsp &nbsp              'model_Bayes_MAP_withCard','model_Bayes_MAP',... <br>
           &nbsp &nbsp &nbsp &nbsp &nbsp               'model_Bayes_MAP_FatTailPrior'}; <br><br>
                         
           >> path = '/Volumes/DroboBKUP/data/dataPsychophy/...<br>
          &nbsp &nbsp &nbsp &nbsp &nbsp          proj01_priorStrength/modelfit/AIC/'; <br><br>
           
           >> [AICsvsSw,semAICsvsSw,aicDiff] = slPlotModelsAICvsSwitchingAIC(model_ref,...<br>
           &nbsp &nbsp &nbsp &nbsp &nbsp               models,path); 
        </code>
        
        <!--code  -->
        <code class="code">
              >> model_ref = 'model_CompDiv'; <br><br>
              >> models = {'model_Bayes_Sampling','model_Bayes_Sampling_withCard',...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp              'model_Bayes_WJMtailedPrior', ... <br>
              &nbsp &nbsp &nbsp &nbsp &nbsp              'model_Bayes_WJM','model_Bayes_MAP_withCard',... <br>
              &nbsp &nbsp &nbsp &nbsp &nbsp              'model_Bayes_MAP',...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp              'model_Bayes_MAP_FatTailPrior'}; <br><br>
              
              >> path = '/Volumes/DroboBKUP/data/dataPsychophy/...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp          proj01_priorStrength/modelfit/AIC/'; <br><br>
              
              >> [AICsvsSw,semAICsvsSw,aicDiff] = slPlotModelsAICvsSwitchingAIC(...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp               model_ref,models,path);
        </code>
        
        <p> We also examined the number of subjects for which switching outperformed the other Bayesian observers </p>
        
        <!--code  -->
        <code class="code">
           >> cd('~/proj/steeve/projInference/data/) <br><br>
           
           >> [rowheader,colheader,data] = slcsvRead('modelfitData.csv'); <br><br>
           
           >> [nRefWins,nNoWin,nRefLoses] = slPlotPropSubSwitchingVsBayesModels(rowheader,...<br><br>
           &nbsp &nbsp &nbsp &nbsp &nbsp                colheader,data,'Switching observer')
        </code>
  
        <!--section-->
        <p> An alternative hypothesis is that subjects simply switched biased their estimates toward the previous motion directions without 
        learning the statistics of the motion directions over trials which is a heuristic that have already been used successfully to 
        explained perceptual behavior [Loewenstein et al.,]. So we looked at where subjects averaged estimates lied in the trials in
        which the currently displayed direction was in between the previous direction (clockwise to the displayed direction) and the 
        prior mean (counterclockwise to the displayed direction). We first checked whether subjects were significantly biased toward 
        the prior mean, thus away from the previous direction over subjects and conditions. </p>
        
        <!--code  -->
        <code class="code">        
           >> [SigBias2priorAll,SigBias2prevdir,marginAll,ciAll,mAll,sAll] = ...<br> 
            &nbsp &nbsp &nbsp &nbsp &nbsp        slplotandStatsPrevDirvsPriorBias({'sub01','sub02','sub03',...<br> 
            &nbsp &nbsp &nbsp &nbsp &nbsp        'sub04','sub05','sub06','sub07','sub08','sub09','sub10',...<br> 
            &nbsp &nbsp &nbsp &nbsp &nbsp        'sub11','sub12'},'~/data/dataPsychophy/proj01_priorStrength/');
        </code>
        
         <p> The overall bias over all subject trials was 4.35 deg, 95% CI [ 3.14 5.57 ] toward the prior and the bias was significantly different 
         from 0 indicating than subjects were on average significantly biased toward the prior and not the previous direction.</p>
        
        <p>We further checked whether all subjects biased their estimates toward the prior and not the previous direction </p>
        
        <!--code  -->
        <code class="code">
           >> [SigBias2priorAll, SigBias2prevdir, marginAll,ciAll,mAll,sAll] = ... </br>
            &nbsp &nbsp &nbsp &nbsp &nbsp        slplotandStatsPrevDirvsPriorBias({'sub01'},'~/data/... </br>
            &nbsp &nbsp &nbsp &nbsp &nbsp        dataPsychophy/proj01_priorStrength/'); </br>
        </code>
        
        <p> 4 out of 12 subjects were significantly biased toward the prior mean and not the previous direction (the average distance
        between the estimate and the current direction was 2.93 deg, 95% CI [0.03 5.82] for subject 1;
        21.40 deg, 95% CI [17.30 25.51] for subject 2; 7.29 deg, 95% CI [4.55 10.02] for subject 4; 
        12.24 , 95% CI [ 6.70 17.78 ] for subject 10; all toward the prior </p>
      
        <p> The remaining 8 out of 12 subjects were not significantly biased neither toward the prior nor toward the previous direction 
        (the average distance between the estimate and the current direction was 
        -0.56 deg, 95% CI [-5.66 4.55] for subject 4; -2.25 deg, 95% CI [-7.39 2.88] for subject 5; -0.43 deg, 95% CI [-4.18 3.32] 
        for subject 6; 1.30 deg, 95% CI [-2.75 5.35] for subject 7; -1.99 deg, 95% CI [ -7.59 3.62 ] for subject 8;
        3.97 deg, 95% CI [0.57 7.38] for subject 9; 1.57 deg, 95% CI [ -2.34 5.49 ] for subject 11;  1.38 deg, 95% CI [-3.97 6.72]
        for subject 12.</p>



        <!--section-->        
        <h7><a id="Eye-movement" class="anchor" href="#lars" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top"> EYE POSITIONS </a></h7> 
        <p> We examined whether subjects eye positions changed between prior conditions. <p>
        <p><strong>Data munging:</strong> We get raw data measured by our eyetracker (.edf files saved on local computer in "rawpath"), format and moved them to easily usable formats (.mat and .csv) in the project folder ("projInference") cloned in "irootpath" like that : </p>
        <!-- Code -->
        <code class="code">
            rawpath = '~/data/dataPsychophy/proj01_priorStrength/data'; <br>
            irootpath = '~/proj/steeve/'; <br>
            subject = {'sub01','sub02','sub03','sub04','sub05','sub06','sub07',... <br>
            &nbsp &nbsp &nbsp &nbsp &nbsp  'sub08','sub09','sub10','susb11','sub12'}; <br>
            iMungeEyeData(subjects,rawpath,irootpath)
        </code>    
        <p> You can access the munged data files : <a href="data/eye" class="class2"> here </a></p>

        <p><strong>Analysis:</strong> I extracted the eye's horizontal (x) and vertical (y) positions (2 x N trials matrix) for each prior and run an hotelling $T^2$ test for each pair of priors (all pairwise combinations of 4 priors = 6 Hotelling $T^2$ test) which is something like that : </p>

        <!-- Code -->
        <code class="code">
            irootpath = '/proj/steeve/projInference/'; <br>
            subject = 'sub01'; <br>
            iAnalEyePosHotellingT2(subject,irootpath)
        </code> 


        <p>We also tested the hypothesis that eye positions are the same between prior conditions with two anovas one over the horizontal and one over the vertical position (for now from raw data on local computer).</p>
        <!--code  -->
        <code class="code">
           datapath = '~/data/dataPsychophy/proj01_priorStrength/data'; <br>
           [dataEye01,output] = SLanalysesEyeMvt({'sub01'},'dataPath',datapath,...<br>
           'AnovaEyeMvt','plotEyeMvtStats','filename','test');
        </code>
        
        <p> The eye distance to the fixation point, averaged over subjects, was not significantly different between priors </p>
        <code class="code">
           >> cd ~/.../projInference/data; <br>
           >> [rowheader,colheader,data] = slcsvRead('data_meanEyePosition.csv'); <br>
           >> [m,ci,condition] = sleyePosMeanAndCIByPrior(data);
        </code>


       <!--section-->
      <p><h7><a id="Generalization-to-another-task" class="anchor" href="#Generalization-to-another-task" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a><a href="#top">GENERALIZATION TO ANOTHER TASK</a></h7> </p>
      <p> We examined whether the result generalized to other tasks and thus run a location estimation task where subject had to estimate the location
      of a noisy wedge (10%, 15,6% and 100% contrast) on a noisy background.  </p>

      <p> The stimulus consisted in a wedge (2.5 deg radius, 5 deg angle span). I generated a wedge, filled it with random values, low pass-filtered 
      the wedge with a 2D Gaussian filter function (30 deg std, centered on zero frequency) and superimposed the filtered wedge on a gray background. Noise was further added to the wedge 
      stimulus by manipulating its contrast from 1%, 15.6% to 100% contrast across trials based on Michelson (Imax - Imin)/(Imax + Imin) (or Weber produce the same results 
      in our case: (I - Ib)/Ib) where I is the intensity (Ib background Intensity).</p>      
      
      <p> To run a run of the task with a prior of 80 deg just run this in matlab (you need mgl installed) : </p>
      
      <!--Code-->
      <code class="code">
          >> sltaskLoc('displayName=VPixx','computeStim','p=80');
      </code>
      
      
      <!--Code-->
      <code class="code">
        >> SLfitBayesianModel({'sub01','sub02','sub03','sub04','sub05','sub06'},...<br>
        &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp    ones(1,11),... <br>
        &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp   'dataPathVM',datapath,'experiment','vonMisesPrior',...<br>
        &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp   'MAPReadout','modelPredictions','withData',...<br>
        &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp   'directoryFitParameter','../modelfit/AIC/',... <br>
        &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp   'filename','locationTask'); <br>
      </code>
      
      <!--End Main Content-->
      </section>
    </div>
    
   
    
    
    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Projinference maintained by <a href="https://github.com/steevelaquitaine">steevelaquitaine</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

  </body>
</html>
