<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Project inference : Design an experiment which requires human subjects to do inference, analyse, mine and model their behavior to understand whether/how they do inference ?">
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">
    <link rel="stylesheet" href="fonts/Serif/cmun-serif.css" />
  </head>

  <body>
    
    <title>How do we make visual inference</title>
    
    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/steevelaquitaine/projInference">Github</a>
          <a id="project_author" href="http://steevelaquitaine.blogspot.com">Steeve laquitaine </a>
        </header>
    </div>

    <!--TITLE-->
    <div id="proj_title_wrap" class="outer">
        <header class="inner">
        <section id="proj_title" class="inner">
        <h1 id="proj_title"> How do we make visual inference ? </h1>
    </div>
    
    <!--Table of contents    -->
     <div id="Table_of_content_wrap" class="outer">
      <section id="table_of_content" class="inner">
        <h5> TABLE OF CONTENTS </h5>
        <h6><a href="#Inference"> INFERENCE <br></h7>
        <h7><a href="#Example-of-an-inference-task">EXAMPLE OF AN INFERENCE TASK <br></h7>
        <h7><a href="#Task-noise-&-statistics-affect-estimation">EFFECT OF TASK NOISE & STATISTICS <br></h7>
        <h7><a href="#Humans-approximate-optimality">HUMANS APPROXIMATE OPTIMALITY <br></h7>
        <h7><a href="#Humans-quickly-learn-complex-statistics">HUMANS QUICKLY LEARN COMPLEX STATISTICS <br></h7>
        <h7><a href="#Eye-movement"> EYE POSITIONS <br></h7>
      </section>
    </div>
    
    
    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
          
        <h6><a id="Inference" class="anchor" href="#Inference" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>INFERENCE</h3>  
        <p> Three main theories have been proposed as to how humans solve inference problems. 1) Humans might be rational : they use optimal statistical solutions to inference problems or 2) 
        irrational and produce maladaptive solutions to inference problems or 3) they use heuristics computational shortcuts that approximate optimal solutions. This fits in with Herbert 
        Simon theory of bounded rationality according to which humans use satisficing solutions (sufficient and satisfying) (Gigerenzer, Psychological 
        review 1996)</p>
  
        <h6><a id="" class="anchor" href="#Example-of-an-inference-task" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>EXAMPLE OF AN INFERENCE TASK </h3>
        <p> We used a stimulus that has been used extensively in the psychophysics literature and that allows to manipulate sensory noise and also subjects priors : the random dot motion stimulus 
        This stimulus is composed of signal dots moving in the same (coherent) directions and noise dots that move in random dots and render the estimation of the motion direction
        difficult. We manipulated the difficulty of estimation by changing the proportion of dots moving coherently (6, 12 or 24%), thus the signal to noise ratio of the motion as follows : </p>
        
        <!--video-->
        <div id="videoal" align ="center" style="padding:10px">
            <div class="video">
                <video controls autoplay>
                    <source src="images/motioncoh06.mp4" type="video/mp4">
                </video>
            </div>
            <div class="video">
               <video controls autoplay>
                    <source src="images/motioncoh12.mp4" type="video/mp4">
               </video>
            </div>
            <div class="video">
               <video controls autoplay>
                    <source src="images/motioncoh24.mp4" type="video/mp4">
               </video>
            </div>
        </div>
        
        <p>We designed a motion direction estimation experiment in which humans were asked to estimate the motion direction of the noisy motions on 
        <center><img src="images/exp.png" style="width: 75%; height: 75%"></center>
        
        <p>In this experiment statistical optimality can be achieved by combining noisy evidence of the motion with knowledge of the motion 
        direction statistics learnt over motion stimulus history using Bayesian inference</p>
        <!--figure-->
        <center><img src="images/BayesHypo.png" style="width: 75%; height: 75%"></center>      
        
        <!--Section-->
        <h6><a id="Task-noise-&-statistics-affect-estimation" class="anchor" href="#Task-noise-&-statistics-affect-estimation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>EFFECT OF TASK NOISE & STATISTICS</h3>
        <p> We looked at subjects average estimates for each displayed motion directions, for different level of noise in the stimulus (from 6% to 24% motion coherence) and 
        different distributions of the motion direction (distribution standard deviation of 80º, 40º, 20º and 10º with fixed mean at 225º).</p>
        
        <!--Code-->
        <code class="code">
            >> datapath = slgetdatapath('lab'); <br><br>

            >> [fitP,fitPbkp,R2,sdata,fitPt,negLogl,negLoglbkp,... <br>
                Logl_pertrialBestfit,output] = SLfitBayesianModel({'sub01','sub02',... <br>
                'sub03','sub04','sub05','sub06','sub07','sub08','sub09','sub10',... <br>
                'sub11','sub12'},[NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN],... <br>
                'dataPathVM',datapath,'experiment','vonMisesPrior',... <br>
                'MAPReadout','modelPredictions','withData',... <br>
                'directoryFitParameter','../modelfit/AIC/',... <br>
                'filename','fig03_04');
        </code>
    
        <p>The Bayesian observer predicted subject estimate mean and variability very well...</p>
        <!--figure-->
        <center><img src="images/BayesFit_meanvar.png" style="width: 75%; height: 75%"/></center>   
        
        <p> ... But it failed to explain the subjects' estimates distribution pattern formed over trials: where the model predicts unimodal distributions, 
        subjects estimate distribution were clearly bimodal.</p>
        <!--figure-->
        <center><img src="images/BayesFit_dis.png" style="width: 55%; height: 55%"/></center>   
        
        <p>The behavior rather posits for an model in which people do not integrate their prior and sensory likelihood in a posterior that 
        estimate that lie in between the two but rather switch between the two representations. </p>
        <!--figure-->
        <center><img src="images/SwitchingAndFits.png" style="width: 75%; height: 75%"/></center>  
        
        <p>We tested other plausible Bayesian observers but all failed to explain the data better than the switching observer </p>
        <!--figure-->
        <center><img src="images/AICsFailureModes.png.png"></center>
        
        <p>We also tested whether subject did not learn priors but simply relied on the previous trial displayed motion direction 
        (a recency strategy). However the data clearly indicate that subjects were biased toward the prior mean and not the previous 
        trial and that the stronger the prior and the stronger their bias toward the prior mean, indicating that subjects learn and 
        used the prior mean and strengths. </p>
        <!--figure-->
        <center><img src="images/RecencyBias.png" style="width: 50%; height: 50%"/></center>
        
        <p>The bias was also the largest for directions displayed the nearest to the prior mean and the smallest on the 
        opposite side of the prior, producing a nonlinear relationship between displayed and estimated directions. 
        This effect is due to the circularity of the space: the average bias become smaller when directions are displayed 
        further from the prior because the evidence is more and more likely to be pulled from both sides of the prior which 
        reduces the average bias. This decreasing bias with increasing distance effect effectively disappears in a linear 
        space as the evidence is always pulled from one side of the prior.
        
        <p>The variability was also the lowest for directions displayed the nearest to the prior mean and the largest 
        on the opposite side of the prior. This effect was due to the same reason that the average bias decreased further 
        from the prior: evidence were more often pulled from both sides of the prior which increased estimate dispersion.<p>
        
        <!--Code-->
        <code class="code">
        >> slsimulateBayesianModelEstimateSpace(5:20:360); 
        </code>
        
        <!--figure-->
        <center><img src="images/BiasAndVarInCircularVsLinearSpace.png"></center>
  
        <!--Head-->
        <h6><a id="Humans-quickly-learn-complex-statisticss" class="anchor" href="#Humans-quickly-learn-complex-statistics" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>HUMANS QUICKLY LEARN COMPLEX STATISTICS</h3>
        <p>A Bayesian observer that uses the statistical distribution of motion directions fit the data beter than a maximum likelihood observer that only uses sensory likelihood. This indicates that subjects incoporated and ued prior 
        knowledge about environment statistics for inference and did not solely rely on the sensory evidence. </p>
        
        <!--code  -->
        <code class="code">
              >> bo = [77182.68 74175.23 84145.32 46451.09 61913.16 75357.9 54584.24 62731.75 84927.68 62633.63 63233.81 66099.47]; <br><br>
              
              >> mlo = [100803.6 92739.7 110810.02 56504.8 68159.3 88925.5 68253.5 68253.5 101627.7 71161.2 76223.3 76223.3]; <br><br>
              
              >> [e,ci,m,s] = slMakeCI(bo,0.95) <br><br>
              
              >> [e,ci,m,s] = slMakeCI(mlo,0.95)
        </code>
  
        <p> This is even clearer when loooking at the AIC difference between the two models, averaged over subjects </p>
        <!--code  -->
        <code class="code">
            >> [e,ci,m,s] = slMakeCI(mlo - bo,0.95);
        </code>
  
        <!--code  -->
        <code class="code">
             >> model_ref = 'model_CompDiv'; <br><br>
             
             >> models = {'model_Bayes_MAP'}; <br><br>
             
             >> path = '/Volumes/DroboBKUP/data/dataPsychophy/... <br>
                        &nbsp &nbsp &nbsp &nbsp &nbsp proj01_priorStrength/modelfit/AIC/'; <br>
             
             >> [~,~,aicDiff01] = slPlotModelsAICvsSwitchingAIC(model_ref,models,path); <br><br>

             >> figure('color','w') ; SLdrawBar(aicDiff01,1:12,1:12,'facecolor',[.5 .5 .5]);
        </code>
        
        <!--figure-->
        <center><img src="images/AICbayesVsSwitch.png" style="width: 50%; height: 50%"/></center>   
        
        
        <!--section-->
        <p> We examined the fit parameters used to model subject prior strengths with the switching observer to determine whether subjects had accurate representations 
        of the spread of the motion direction statistical distribution over trials (experimental prior). We compared the subjective prior strengths prescribed by 
        the switching observer with those predicted by the Basic Bayesian observer. </p>
        
        <!--figure here median prior strengths-->

        <p> We tested whether the switching observers predicted strength were statistically more accurate than the strengths predicted by the Bayesian observer.
        Most prior strengths were not normally distributed across subjects (lilliest, most p < 0.05) : </p>
        
        <!--Code-->
        <code class="code">
          >> cd('~/proj/steeve/projInference/data/') <br><br>
          
          >> [~,~,data] = slcsvRead('data_PriorStrngths.csv'); <br><br>
          
          >> [Pbo,Psw,subBOstd,subswstd] = slIsPriorStrgDisNormal(data);
        </code>
        
        <p> So we compared the median over subjects of the four subjective prior strength parameters fitted by the switching observer to 
        each subject’s data (Fig. 6b) to veridical strength  and found that although the switching observer’s median fitted prior 
        over subjects were significantly weaker than the 80º and 40º veridical priors (W = 7, p < 0.01 and W = 0, p < 0.01 
        respectively, one-sample Wilcoxon test), the switching observer’s fitted prior standard deviations for the 20º and 10º 
        priors did not significantly differ from the veridical prior standard deviations (W=17, p=0.09 and W=27, p=0.38 for the 
        20 and 10 deg priors, one-sample Wilcoxon test). In contrast, the Basic Bayesian observer’s median fitted priors over 
        subjects were all significantly weaker than the veridical priors (W=1, W=1, W=3, W=2, all p<0.01, for the 80, 40, 20 
        and 10 deg priors respectively, one-sample Wilcoxon test) which would suggest that the observers were unable to make accurate 
        estimates of the prior distribution. </p>
        
        <!--Code-->
        <code class="code">  
            >> [pbo,psw,Hbo,Hsw,wbo,wsw] = slcompBoandSwPriorStrgToExp(subBOstd,...<br>
                                             &nbsp &nbsp &nbsp &nbsp &nbsp subswstd,subExpstd);
        </code>   
        
        <p> We tested various other plausible Bayesian observers, relaxing certain assumptions about how subject brain might represent the 
        likelihood and priors, or how their brain might read out those information. We were inspired by models that have been used by past studies
        to explain other aspects of perception :
        - a basic Bayesian model [Stocker 2006; Girshick 2011] <br>
        - a sampling Bayesian model [Pouget 2011] <br>
        - a basic Bayesian model with cardinal priors [Stocker 2006; Girshick 2011]<br>
        - a basic Bayesian model with likelihood computed from stimulus components [Stocker 2006; Girshick 2011]<br>
        - Hierarchical Bayesian inference [Mumford 2003]<br>
        </p>
      
        <!--code-->
        <code class="code">
             >> model_ref = 'model_CompDiv'; <br> 
             
             >> models = {'model_Bayes_Sampling','model_Bayes_Sampling_withCard',...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp             'model_Bayes_WJMtailedPrior','model_Bayes_WJM',...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp             'model_Bayes_MAP_withCard',...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp             'model_Bayes_MAP','model_Bayes_MAP_FatTailPrior'}; <br><br>
                           
             >> path = '~/data/dataPsychophy/proj01_priorStrength/modelfit/AIC/'; <br><br>
             
             >> [AICsvsSw,semAICsvsSw,aicDiff] = slPlotModelsAICvsSwitchingAIC(model_ref,...<br>
            &nbsp &nbsp &nbsp &nbsp &nbsp                                   models,path); 
        </code>
        
        
        <!--Figure-->
        <center><img src="images/WhyBayesianObserversFail.png" style="width: 100%; height: 100%"/></center>
        
        <p> We examined how well other Bayesian observers fit the data compared to the switching observer
        
        <!--code  -->
        <code class="code">
           >> model_ref = 'model_CompDiv'; <br><br>
           
           >> models = {'model_Bayes_Sampling','model_Bayes_Sampling_withCard',...<br>
           &nbsp &nbsp &nbsp &nbsp &nbsp               'model_Bayes_WJMtailedPrior','model_Bayes_WJM',...<br>
           &nbsp &nbsp &nbsp &nbsp &nbsp              'model_Bayes_MAP_withCard','model_Bayes_MAP',... <br>
           &nbsp &nbsp &nbsp &nbsp &nbsp               'model_Bayes_MAP_FatTailPrior'}; <br><br>
                         
           >> path = '/Volumes/DroboBKUP/data/dataPsychophy/...<br>
          &nbsp &nbsp &nbsp &nbsp &nbsp          proj01_priorStrength/modelfit/AIC/'; <br><br>
           
           >> [AICsvsSw,semAICsvsSw,aicDiff] = slPlotModelsAICvsSwitchingAIC(model_ref,...<br>
           &nbsp &nbsp &nbsp &nbsp &nbsp               models,path); 
        </code>
        
        <!--code  -->
        <code class="code">
              >> model_ref = 'model_CompDiv'; <br><br>
              >> models = {'model_Bayes_Sampling','model_Bayes_Sampling_withCard',...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp              'model_Bayes_WJMtailedPrior', ... <br>
              &nbsp &nbsp &nbsp &nbsp &nbsp              'model_Bayes_WJM','model_Bayes_MAP_withCard',... <br>
              &nbsp &nbsp &nbsp &nbsp &nbsp              'model_Bayes_MAP',...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp              'model_Bayes_MAP_FatTailPrior'}; <br><br>
              
              >> path = '/Volumes/DroboBKUP/data/dataPsychophy/...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp          proj01_priorStrength/modelfit/AIC/'; <br><br>
              
              >> [AICsvsSw,semAICsvsSw,aicDiff] = slPlotModelsAICvsSwitchingAIC(...<br>
              &nbsp &nbsp &nbsp &nbsp &nbsp               model_ref,models,path);
        </code>
        
        <p> We also examined the number of subjects for which switching outperformed the other Bayesian observers </p>
        
        <!--code  -->
        <code class="code">
           >> cd('~/proj/steeve/projInference/data/) <br><br>
           
           >> [rowheader,colheader,data] = slcsvRead('modelfitData.csv'); <br><br>
           
           >> [nRefWins,nNoWin,nRefLoses] = slPlotPropSubSwitchingVsBayesModels(rowheader,...<br><br>
           &nbsp &nbsp &nbsp &nbsp &nbsp                colheader,data,'Switching observer')
        </code>
  
        <!--section-->
        <p> An alternative hypothesis is that subjects simply switched biased their estimates toward the previous motion directions without 
        learning the statistics of the motion directions over trials which is a heuristic that have already been used successfully to 
        explained perceptual behavior [Loewenstein et al.,]. So we looked at where subjects averaged estimates lied in the trials in
        which the currently displayed direction was in between the previous direction (clockwise to the displayed direction) and the 
        prior mean (counterclockwise to the displayed direction). We first checked whether subjects were significantly biased toward 
        the prior mean, thus away from the previous direction over subjects and conditions. </p>
        
        <!--code  -->
        <code class="code">        
           >> [SigBias2priorAll,SigBias2prevdir,marginAll,ciAll,mAll,sAll] = ...<br> 
            &nbsp &nbsp &nbsp &nbsp &nbsp        slplotandStatsPrevDirvsPriorBias({'sub01','sub02','sub03',...<br> 
            &nbsp &nbsp &nbsp &nbsp &nbsp        'sub04','sub05','sub06','sub07','sub08','sub09','sub10',...<br> 
            &nbsp &nbsp &nbsp &nbsp &nbsp        'sub11','sub12'},'~/data/dataPsychophy/proj01_priorStrength/');
        </code>
        
         <p> The overall bias over all subject trials was 4.35 deg, 95% CI [ 3.14 5.57 ] toward the prior and the bias was significantly different 
         from 0 indicating than subjects were on average significantly biased toward the prior and not the previous direction.</p>
        
        <p>We further checked whether all subjects biased their estimates toward the prior and not the previous direction </p>
        
        <!--code  -->
        <code class="code">
           >> [SigBias2priorAll, SigBias2prevdir, marginAll,ciAll,mAll,sAll] = ... </br>
            &nbsp &nbsp &nbsp &nbsp &nbsp        slplotandStatsPrevDirvsPriorBias({'sub01'},'~/data/... </br>
            &nbsp &nbsp &nbsp &nbsp &nbsp        dataPsychophy/proj01_priorStrength/'); </br>
        </code>
        
        <p> 4 out of 12 subjects were significantly biased toward the prior mean and not the previous direction (the average distance
        between the estimate and the current direction was 2.93 deg, 95% CI [0.03 5.82] for subject 1;
        21.40 deg, 95% CI [17.30 25.51] for subject 2; 7.29 deg, 95% CI [4.55 10.02] for subject 4; 
        12.24 , 95% CI [ 6.70 17.78 ] for subject 10; all toward the prior </p>
      
        <p> The remaining 8 out of 12 subjects were not significantly biased neither toward the prior nor toward the previous direction 
        (the average distance between the estimate and the current direction was 
        -0.56 deg, 95% CI [-5.66 4.55] for subject 4; -2.25 deg, 95% CI [-7.39 2.88] for subject 5; -0.43 deg, 95% CI [-4.18 3.32] 
        for subject 6; 1.30 deg, 95% CI [-2.75 5.35] for subject 7; -1.99 deg, 95% CI [ -7.59 3.62 ] for subject 8;
        3.97 deg, 95% CI [0.57 7.38] for subject 9; 1.57 deg, 95% CI [ -2.34 5.49 ] for subject 11;  1.38 deg, 95% CI [-3.97 6.72]
        for subject 12.</p>

  
        <!--section-->
        <h6><a id="Eye-movement" class="anchor" href="#Eye movement" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>EYE POSITION</h3> 
        <p> We examined whether subjects eye positions changed between prior conditions.  </p>
        
        <!--code  -->
        <code class="code">
           >> datapath = '~/../myProjData/'; <br><br>
           
           >> [eyedatabank,output] = SLanalysesEyeMvt({'sub01'},'dataPath',datapath,...<br>
           &nbsp &nbsp &nbsp &nbsp &nbsp             'AnovaEyeMvt','plotEyeMvtStats','filename','test');
        </code>
        
        <p> The eye positions averaged over subjects did not significantly change between priors </p>
        <code class="code">
           >> cd ~/.../projInference/data; <br><br>
           
           >> [rowheader,colheader,data] = slcsvRead('data_meanEyePosition.csv'); <br><br>
           
           >> [m,ci,condition] = sleyePosMeanAndCIByPrior(data);
        </code>

      <!--End Main Content-->
      </section>
    </div>
    
    
    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Projinference maintained by <a href="https://github.com/steevelaquitaine">steevelaquitaine</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

  </body>
</html>
